{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f4c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNetwork import NNetwork\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845629bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=32, learning_rate=0.01, epochs=10, verbose=1, reg_type=\"L1\"):\n",
    "    \"\"\"\n",
    "    Melatih model dengan parameter yang diberikan.\n",
    "\n",
    "    :param model: Objek dari NNetwork.\n",
    "    :param X_train: Data training (numpy array, shape: (num_samples, num_features))\n",
    "    :param y_train: Label training (numpy array, shape: (num_samples, num_classes))\n",
    "    :param X_val: Data validasi (numpy array, shape: (num_samples, num_features))\n",
    "    :param y_val: Label validasi (numpy array, shape: (num_samples, num_classes))\n",
    "    :param batch_size: Jumlah sampel per batch saat training.\n",
    "    :param learning_rate: Learning rate untuk gradient descent.\n",
    "    :param epochs: Jumlah epoch untuk training.\n",
    "    :param verbose: 0 = tanpa output, 1 = progress bar + training & validation loss.\n",
    "    :return: Dictionary berisi histori training loss & validation loss tiap epoch.\n",
    "    \"\"\"\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    num_samples = X_train.shape[0]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        num_batches = num_samples // batch_size\n",
    "\n",
    "        batch_iterator = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{epochs}\", disable=(verbose == 0))\n",
    "\n",
    "        for batch_idx in batch_iterator:\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            X_batch, y_batch = X_train[start_idx:end_idx], y_train[start_idx:end_idx]\n",
    "\n",
    "            loss = model.backward_propagation(X_batch, y_batch, learning_rate, reg_type)\n",
    "            epoch_loss += loss\n",
    "\n",
    "            if verbose == 1:\n",
    "                batch_iterator.set_postfix(train_loss=loss)\n",
    "\n",
    "        train_loss = epoch_loss / num_batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "\n",
    "        val_preds = model.forward_propagation(X_val)\n",
    "        val_loss = np.mean((val_preds - y_val) ** 2)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        if verbose == 1:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.5f}, Val Loss: {val_loss:.5f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412916ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "X= X / 255\n",
    "y = np.array(y).astype(int)  # Convert to integers\n",
    "num_classes = 10  # since labels are from 0 to 9\n",
    "y = np.eye(num_classes)[y]\n",
    "\n",
    "# X = X[:1000]\n",
    "# y = y[:1000]\n",
    "\n",
    "Xtrain = X[:5600]\n",
    "ytrain = y[:5600]\n",
    "Xval = X[5600:]\n",
    "yval = y[5600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78d1cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inisiasi layer 0\n",
      "inisiasi node selesai\n",
      "inisiasi layer 1\n",
      "inisiasi node selesai\n",
      "inisiasi layer 2\n",
      "inisiasi node selesai\n",
      "inisiasi layer 3\n",
      "inisiasi node selesai\n",
      "inisiasi layer selesai\n",
      "âœ… Jaringan saraf dengan 4 layer berhasil dibuat!\n",
      "ðŸ”¹ Layer 0 (Input) - 784 neurons\n",
      "ðŸ”¹ Layer 1 - 16 neurons, Aktivasi: sigmoid\n",
      "ðŸ”¹ Layer 2 - 16 neurons, Aktivasi: sigmoid\n",
      "ðŸ”¹ Layer 3 - 10 neurons, Aktivasi: softmax\n",
      "inisiasi layer 0\n",
      "inisiasi node selesai\n",
      "inisiasi layer 1\n",
      "inisiasi node selesai\n",
      "inisiasi layer 2\n",
      "inisiasi node selesai\n",
      "inisiasi layer 3\n",
      "inisiasi node selesai\n",
      "inisiasi layer selesai\n",
      "âœ… Jaringan saraf dengan 4 layer berhasil dibuat!\n",
      "ðŸ”¹ Layer 0 (Input) - 784 neurons\n",
      "ðŸ”¹ Layer 1 - 16 neurons, Aktivasi: sigmoid\n",
      "ðŸ”¹ Layer 2 - 16 neurons, Aktivasi: sigmoid\n",
      "ðŸ”¹ Layer 3 - 10 neurons, Aktivasi: softmax\n",
      "inisiasi layer 0\n",
      "inisiasi node selesai\n",
      "inisiasi layer 1\n",
      "inisiasi node selesai\n",
      "inisiasi layer 2\n",
      "inisiasi node selesai\n",
      "inisiasi layer 3\n",
      "inisiasi node selesai\n",
      "inisiasi layer selesai\n",
      "âœ… Jaringan saraf dengan 4 layer berhasil dibuat!\n",
      "ðŸ”¹ Layer 0 (Input) - 784 neurons\n",
      "ðŸ”¹ Layer 1 - 16 neurons, Aktivasi: sigmoid\n",
      "ðŸ”¹ Layer 2 - 16 neurons, Aktivasi: sigmoid\n",
      "ðŸ”¹ Layer 3 - 10 neurons, Aktivasi: softmax\n"
     ]
    }
   ],
   "source": [
    "nn1 = NNetwork(4 , [784, 16, 16, 10], verbose=True)\n",
    "nn1.initialize_weights(method=\"normal\", mean=0, variance=0.1, seed=42, verbose=False)\n",
    "nn2 = NNetwork(4 , [784, 16, 16, 10], verbose=True)\n",
    "nn2.initialize_weights(method=\"normal\", mean=0, variance=0.1, seed=42, verbose=False)\n",
    "nn3 = NNetwork(4 , [784, 16, 16, 10], verbose=True)\n",
    "nn3.initialize_weights(method=\"normal\", mean=0, variance=0.1, seed=42, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fa4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 579.87it/s, train_loss=0.0904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.09064, Val Loss: 0.08970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 503.60it/s, train_loss=0.0893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 0.08933, Val Loss: 0.08911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 561.55it/s, train_loss=0.0887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 0.08879, Val Loss: 0.08858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 576.36it/s, train_loss=0.0881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 0.08822, Val Loss: 0.08798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 571.70it/s, train_loss=0.0874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.08758, Val Loss: 0.08729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 579.26it/s, train_loss=0.0866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Loss: 0.08682, Val Loss: 0.08649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 579.94it/s, train_loss=0.0856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 0.08594, Val Loss: 0.08554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 558.62it/s, train_loss=0.0846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Loss: 0.08491, Val Loss: 0.08443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 573.86it/s, train_loss=0.0835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 0.08371, Val Loss: 0.08316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 572.25it/s, train_loss=0.0822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.08236, Val Loss: 0.08174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 524.74it/s, train_loss=0.0906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.09067, Val Loss: 0.08982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 535.25it/s, train_loss=0.0899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 0.08958, Val Loss: 0.08949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 492.44it/s, train_loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 0.08937, Val Loss: 0.08935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 511.25it/s, train_loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 0.08928, Val Loss: 0.08931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 517.15it/s, train_loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.08927, Val Loss: 0.08933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 548.11it/s, train_loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Loss: 0.08930, Val Loss: 0.08937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 525.52it/s, train_loss=0.0897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 0.08935, Val Loss: 0.08943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 495.93it/s, train_loss=0.0898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Loss: 0.08942, Val Loss: 0.08951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 525.93it/s, train_loss=0.0898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 0.08950, Val Loss: 0.08958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 534.00it/s, train_loss=0.0899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.08958, Val Loss: 0.08966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 569.75it/s, train_loss=0.0905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.09064, Val Loss: 0.08971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 571.86it/s, train_loss=0.0895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 0.08939, Val Loss: 0.08921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 514.73it/s, train_loss=0.0889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 0.08896, Val Loss: 0.08882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 551.09it/s, train_loss=0.0885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 0.08857, Val Loss: 0.08844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 561.91it/s, train_loss=0.0881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.08818, Val Loss: 0.08805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 535.72it/s, train_loss=0.0877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Loss: 0.08778, Val Loss: 0.08764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 543.11it/s, train_loss=0.0873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 0.08735, Val Loss: 0.08719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 485.81it/s, train_loss=0.0868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Loss: 0.08688, Val Loss: 0.08671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 552.85it/s, train_loss=0.0863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 0.08637, Val Loss: 0.08617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:00<00:00, 560.77it/s, train_loss=0.0858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.08580, Val Loss: 0.08557\n"
     ]
    }
   ],
   "source": [
    "history1 = train_model(nn1, Xtrain, ytrain, Xval, yval, batch_size=20, learning_rate=0.01, epochs=10, verbose=1, reg_type=\"None\")\n",
    "history2 = train_model(nn2, Xtrain, ytrain, Xval, yval, batch_size=20, learning_rate=0.01, epochs=10, verbose=1, reg_type=\"L1\")\n",
    "history3 = train_model(nn3, Xtrain, ytrain, Xval, yval, batch_size=20, learning_rate=0.01, epochs=10, verbose=1, reg_type=\"L2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ca4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, base_dir=\"hasil\"):\n",
    "    \"\"\"Plot training history and save to a dynamically created folder.\"\"\"\n",
    "    # Cari folder dengan angka berikutnya yang belum ada\n",
    "    i = 1\n",
    "    while os.path.exists(f\"{base_dir}/{i}\"):\n",
    "        i += 1\n",
    "\n",
    "    filename = f\"training_history_{i}.png\"\n",
    "    folder_path = f\"{base_dir}/{i}\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Simpan plot ke file di folder tersebut\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history[\"train_loss\"], label=\"Training Loss\", marker=\"o\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation Loss\", marker=\"s\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(file_path)  # Simpan plot ke file\n",
    "    plt.close()  # Tutup plot untuk menghindari masalah GUI\n",
    "\n",
    "    # Simpan data verbose ke file teks\n",
    "    verbosename = f\"verbose_{i}.txt\"\n",
    "    verbose_file_path = os.path.join(folder_path, verbosename)\n",
    "    with open(verbose_file_path, \"w\") as f:\n",
    "        f.write(json.dumps(history, indent=4))\n",
    "\n",
    "    print(f\"Plot saved to: {file_path}\")\n",
    "    print(f\"Verbose data saved to: {verbose_file_path}\")\n",
    "    return folder_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fffa1246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: hasil/1\\training_history_1.png\n",
      "Verbose data saved to: hasil/1\\verbose_1.txt\n",
      "Plot saved to: hasil/2\\training_history_2.png\n",
      "Verbose data saved to: hasil/2\\verbose_2.txt\n",
      "Plot saved to: hasil/3\\training_history_3.png\n",
      "Verbose data saved to: hasil/3\\verbose_3.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hasil/3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_training_history(history1)\n",
    "plot_training_history(history2)\n",
    "plot_training_history(history3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
